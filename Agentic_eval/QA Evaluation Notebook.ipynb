{"cells":[{"cell_type":"code","source":["%pip install azure-ai-evaluation azure-identity azure-ai-projects openai"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":23,"statement_ids":[19,20,21,22,23],"state":"finished","livy_statement_state":"available","session_id":"8c9e2af0-7250-4f02-a681-e3c8af94e018","normalized_state":"finished","queued_time":"2025-11-11T01:53:10.6689936Z","session_start_time":null,"execution_start_time":"2025-11-11T01:53:10.6694436Z","execution_finish_time":"2025-11-11T01:53:22.7031424Z","parent_msg_id":"dba3c2a7-47d3-4c53-af49-49e204f6e8a9"},"text/plain":"StatementMeta(, 8c9e2af0-7250-4f02-a681-e3c8af94e018, 23, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: azure-ai-evaluation in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (1.13.4)\nRequirement already satisfied: azure-identity in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (1.25.1)\nRequirement already satisfied: azure-ai-projects in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (1.0.0)\nRequirement already satisfied: openai in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (2.7.2)\nRequirement already satisfied: pyjwt>=2.8.0 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from azure-ai-evaluation) (2.10.1)\nRequirement already satisfied: azure-core>=1.31.0 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from azure-ai-evaluation) (1.36.0)\nRequirement already satisfied: nltk>=3.9.1 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from azure-ai-evaluation) (3.9.2)\nRequirement already satisfied: azure-storage-blob>=12.19.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-ai-evaluation) (12.22.0)\nRequirement already satisfied: httpx>=0.27.2 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from azure-ai-evaluation) (0.28.1)\nRequirement already satisfied: pandas<3.0.0,>=2.1.2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-ai-evaluation) (2.1.4)\nRequirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-ai-evaluation) (0.17.21)\nRequirement already satisfied: msrest>=0.6.21 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-ai-evaluation) (0.7.1)\nRequirement already satisfied: Jinja2>=3.1.6 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from azure-ai-evaluation) (3.1.6)\nRequirement already satisfied: aiohttp>=3.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-ai-evaluation) (3.9.3)\nRequirement already satisfied: cryptography>=2.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-identity) (42.0.2)\nRequirement already satisfied: msal>=1.30.0 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from azure-identity) (1.34.0)\nRequirement already satisfied: msal-extensions>=1.2.0 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from azure-identity) (1.3.1)\nRequirement already satisfied: typing-extensions>=4.0.0 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from azure-identity) (4.15.0)\nRequirement already satisfied: isodate>=0.6.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-ai-projects) (0.6.1)\nRequirement already satisfied: azure-ai-agents>=1.0.0 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from azure-ai-projects) (1.1.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (4.2.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (1.8.0)\nRequirement already satisfied: jiter<1,>=0.10.0 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from openai) (0.12.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from openai) (2.12.4)\nRequirement already satisfied: sniffio in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (1.3.0)\nRequirement already satisfied: tqdm>4 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from openai) (4.65.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.2.0)\nRequirement already satisfied: attrs>=17.3.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (23.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.4.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from aiohttp>=3.0->azure-ai-evaluation) (1.9.3)\nRequirement already satisfied: idna>=2.8 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\nRequirement already satisfied: requests>=2.21.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from azure-core>=1.31.0->azure-ai-evaluation) (2.31.0)\nRequirement already satisfied: cffi>=1.12 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from cryptography>=2.5->azure-identity) (1.16.0)\nRequirement already satisfied: certifi in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from httpx>=0.27.2->azure-ai-evaluation) (2024.2.2)\nRequirement already satisfied: httpcore==1.* in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from httpx>=0.27.2->azure-ai-evaluation) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.2->azure-ai-evaluation) (0.16.0)\nRequirement already satisfied: six in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from isodate>=0.6.1->azure-ai-projects) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from Jinja2>=3.1.6->azure-ai-evaluation) (2.1.3)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from msrest>=0.6.21->azure-ai-evaluation) (1.3.0)\nRequirement already satisfied: click in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (8.1.7)\nRequirement already satisfied: joblib in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (1.2.0)\nRequirement already satisfied: regex>=2021.8.3 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (2023.10.3)\nRequirement already satisfied: numpy<2,>=1.23.2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2023.3)\nRequirement already satisfied: annotated-types>=0.6.0 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /nfs4/pyenv-5adda610-d0fe-4b63-9db1-849c1562653b/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\nRequirement already satisfied: pycparser in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.21)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-ai-evaluation) (2.0.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests>=2.21.0->azure-core>=1.31.0->azure-ai-evaluation) (2.1.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.11/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-evaluation) (3.2.2)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"jupyter":{"outputs_hidden":true}},"id":"d82d67ec-b499-4ca6-98ba-c8b0b160391d"},{"cell_type":"code","source":["# ## Step 1: Import Libraries\n","\n","import os\n","import json\n","from datetime import datetime\n","from pyspark.sql.functions import (\n","    col, when, lit, current_timestamp, udf, collect_list,\n","    struct, row_number, avg, count as sql_count\n",")\n","from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType, ArrayType\n","from pyspark.sql.window import Window\n","\n","# Azure AI Evaluation SDK imports\n","from azure.ai.evaluation import (\n","    IntentResolutionEvaluator,\n","    RelevanceEvaluator,\n","    CoherenceEvaluator,\n","    FluencyEvaluator\n",")\n","\n","print(\"Azure AI Evaluation SDK loaded successfully\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":34,"statement_ids":[34],"state":"finished","livy_statement_state":"available","session_id":"8c9e2af0-7250-4f02-a681-e3c8af94e018","normalized_state":"finished","queued_time":"2025-11-11T02:02:42.1417586Z","session_start_time":null,"execution_start_time":"2025-11-11T02:02:42.1429445Z","execution_finish_time":"2025-11-11T02:02:42.7916655Z","parent_msg_id":"641decdc-eecc-4e5a-90ce-93361e6e29d7"},"text/plain":"StatementMeta(, 8c9e2af0-7250-4f02-a681-e3c8af94e018, 34, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Azure AI Evaluation SDK loaded successfully\n"]}],"execution_count":22,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0f9ec18a-6ecf-4b58-9281-c387176a4ffc"},{"cell_type":"code","source":["# ## Step 2: Load Configuration from .env file\n","env_file_path = \"./builtin/.env\"  # Adjust this path as needed\n","\n","print(\"Loading configuration from .env file...\")\n","try:\n","    with open(env_file_path, \"r\") as f:\n","        for line in f:\n","            line = line.strip()\n","            # Skip comments and empty lines\n","            if line and not line.startswith(\"#\") and \"=\" in line:\n","                key, value = line.split(\"=\", 1)\n","                \n","                # Remove quotes from the value\n","                value = value.strip(\"'\\\"\")\n","                \n","                # Set the variable in the environment\n","                os.environ[key] = value\n","                \n","                # Secure printing\n","                if \"KEY\" in key.upper() or \"SECRET\" in key.upper():\n","                    print(f\"  > Loaded: {key} = ***(hidden)***\")\n","                else:\n","                    print(f\"  > Loaded: {key} = {value}\")\n","                    \n","    print(\"\\nSuccessfully loaded configuration from .env file.\")\n","\n","except FileNotFoundError:\n","    raise FileNotFoundError(f\"Error: The .env file was not found at {env_file_path}\")\n","except Exception as e:\n","    raise RuntimeError(f\"Error reading or parsing .env file: {e}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":35,"statement_ids":[35],"state":"finished","livy_statement_state":"available","session_id":"8c9e2af0-7250-4f02-a681-e3c8af94e018","normalized_state":"finished","queued_time":"2025-11-11T02:02:46.6650796Z","session_start_time":null,"execution_start_time":"2025-11-11T02:02:46.6662362Z","execution_finish_time":"2025-11-11T02:02:49.0386472Z","parent_msg_id":"f3886d3f-d918-43f6-881f-9d667320d382"},"text/plain":"StatementMeta(, 8c9e2af0-7250-4f02-a681-e3c8af94e018, 35, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Loading configuration from .env file...\n  > Loaded: AZURE_OPENAI_KEY = ***(hidden)***\n  > Loaded: AZURE_OPENAI_ENDPOINT = https://arnaudaihub2918240993.openai.azure.com/\n  > Loaded: AZURE_OPENAI_DEPLOYMENT = gpt-5-mini\n  > Loaded: AZURE_OPENAI_API_VERSION = 2024-10-21\n  > Loaded: AZURE_OPENAI_DEPLOYMENT2 = gpt-4.1\n\nSuccessfully loaded configuration from .env file.\n"]}],"execution_count":23,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"681b9066-a790-418c-9e1a-58316fe160cc"},{"cell_type":"code","source":["# ## Step 3: Load, Prepare, and Filter Q&A Pairs\n","\n","# --- INCREMENTAL Q&A EVALUATION SYSTEM WITH CONTEXT ---\n","\"\"\"\n","This code:\n","1. Loads all chat history.\n","2. Identifies and aligns Q&A pairs (human -> ai).\n","3. Builds the prior conversation history for each Q&A pair.\n","4. Checks against the scores table to find NEW Q&A pairs that haven't been evaluated.\n","5. Creates the final 'df_new_qa_pairs' DataFrame for evaluation.\n","\"\"\"\n","\n","from pyspark.sql.functions import col, current_timestamp, lit, lag, array, when\n","from pyspark.sql import DataFrame\n","\n","# ============================================================================\n","# CONFIGURATION\n","# ============================================================================\n","SOURCE_TABLE = \"dbo.chat_history\"\n","ALIGNED_QA_TABLE = \"dbo.chat_qa_pairs_aligned\" # This can be used for logging, but not required for eval\n","SCORES_TABLE = \"dbo.AnswerQualityScores_WithContext\"\n","\n","USER_MESSAGE_TYPE = 'human'\n","AGENT_MESSAGE_TYPE = 'ai'\n","\n","# ============================================================================\n","# Check/Create Tables\n","# ============================================================================\n","def ensure_tables_exist():\n","    \"\"\"Ensure the necessary tables exist with proper schema.\"\"\"\n","    try:\n","        existing_scores = spark.read.table(SCORES_TABLE)\n","        print(f\"✓ Scores table '{SCORES_TABLE}' exists with {existing_scores.count()} records\")\n","    except Exception as e:\n","        print(f\"! Scores table '{SCORES_TABLE}' doesn't exist yet - will be created on first run\")\n","    \n","    try:\n","        existing_qa = spark.read.table(ALIGNED_QA_TABLE)\n","        print(f\"✓ Aligned Q&A table '{ALIGNED_QA_TABLE}' exists with {existing_qa.count()} records\")\n","    except Exception as e:\n","        print(f\"! Aligned Q&A table '{ALIGNED_QA_TABLE}' doesn't exist yet - will be created on first run\")\n","\n","ensure_tables_exist()\n","\n","# ============================================================================\n","# Get Already Evaluated Trace IDs\n","# ============================================================================\n","def get_already_evaluated_trace_ids():\n","    \"\"\"Returns a set of trace_ids that have already been evaluated.\"\"\"\n","    try:\n","        df_existing = spark.read.table(SCORES_TABLE)\n","        evaluated_trace_ids = df_existing.select(\"agent_trace_id\").distinct()\n","        count = evaluated_trace_ids.count()\n","        print(f\"\\n{'='*80}\")\n","        print(f\"ALREADY EVALUATED: {count} trace_ids\")\n","        print(f\"{'='*80}\")\n","        return evaluated_trace_ids\n","    except Exception as e:\n","        print(f\"\\n{'='*80}\")\n","        print(f\"FIRST RUN: No existing evaluations found\")\n","        print(f\"{'='*80}\")\n","        return spark.createDataFrame([], \"agent_trace_id STRING\")\n","\n","df_already_evaluated = get_already_evaluated_trace_ids()\n","\n","# ============================================================================\n","# Extract and Align Q&A Pairs\n","# ============================================================================\n","print(\"\\n\" + \"=\"*80)\n","print(\"BUILDING Q&A PAIRS WITH CONVERSATION CONTEXT\")\n","print(\"=\"*80)\n","\n","# Load chat history\n","df_chat_history = spark.read.table(SOURCE_TABLE)\n","total_messages = df_chat_history.count()\n","print(f\"Total messages in chat history: {total_messages}\")\n","\n","# Get only human and AI messages, sorted by session and time\n","df_conversation = df_chat_history.filter(\n","    col(\"message_type\").isin([USER_MESSAGE_TYPE, AGENT_MESSAGE_TYPE])\n",").select(\n","    \"trace_id\",\n","    \"session_id\",\n","    \"user_id\",\n","    \"agent_id\",\n","    \"message_type\",\n","    \"content\",\n","    \"tool_name\",\n","    \"response_time_ms\",\n","    \"model_name\",\n","    \"total_tokens\",\n","    \"completion_tokens\",\n","    \"prompt_tokens\",\n","    \"trace_end\"\n",").orderBy(\"session_id\", \"trace_end\")\n","\n","print(f\"Total conversation messages: {df_conversation.count()}\")\n","\n","# ============================================================================\n","# Build Conversation Context for each message\n","# ============================================================================\n","\n","# Add row number within each session to track conversation order\n","window_spec = Window.partitionBy(\"session_id\").orderBy(\"trace_end\")\n","df_with_order = df_conversation.withColumn(\"turn_number\", row_number().over(window_spec))\n","\n","# Separate questions and answers\n","df_questions = df_with_order.filter(col(\"message_type\") == USER_MESSAGE_TYPE).alias(\"q\")\n","df_answers = df_with_order.filter(col(\"message_type\") == AGENT_MESSAGE_TYPE).alias(\"a\")\n","\n","# Join questions with their answers (same trace_id)\n","df_qa_pairs = df_questions.join(\n","    df_answers,\n","    (df_questions[\"trace_id\"] == df_answers[\"trace_id\"]) &\n","    (df_questions[\"session_id\"] == df_answers[\"session_id\"]),\n","    \"inner\"\n",").select(\n","    col(\"q.trace_id\").alias(\"agent_trace_id\"),\n","    col(\"q.session_id\").alias(\"session_id\"),\n","    col(\"q.user_id\").alias(\"user_id\"),\n","    col(\"q.agent_id\").alias(\"agent_id\"),\n","    col(\"q.content\").alias(\"user_question\"),\n","    col(\"a.content\").alias(\"agent_answer\"),\n","    col(\"q.turn_number\").alias(\"turn_number\"),\n","    col(\"a.tool_name\").alias(\"invoked_tool_name\"),\n","    col(\"a.response_time_ms\").alias(\"response_time_ms\"),\n","    col(\"a.model_name\").alias(\"model_name\"),\n","    col(\"a.total_tokens\").alias(\"total_tokens\"),\n","    col(\"a.completion_tokens\").alias(\"completion_tokens\"),\n","    col(\"a.prompt_tokens\").alias(\"prompt_tokens\"),\n","    col(\"q.trace_end\").alias(\"trace_end\")\n",").filter(\n","    col(\"user_question\").isNotNull() & col(\"agent_answer\").isNotNull()\n",")\n","\n","total_qa_pairs = df_qa_pairs.count()\n","print(f\"Total Q&A pairs: {total_qa_pairs}\")\n","\n","# ============================================================================\n","# Build Conversation History for each Q&A pair\n","# ============================================================================\n","\n","# Self-join to get previous Q&A pairs in the same session\n","df_with_history = df_qa_pairs.alias(\"current\").join(\n","    df_qa_pairs.alias(\"previous\"),\n","    (col(\"current.session_id\") == col(\"previous.session_id\")) &\n","    (col(\"current.turn_number\") > col(\"previous.turn_number\")),\n","    \"left\"\n",").groupBy(\n","    col(\"current.agent_trace_id\"),\n","    col(\"current.session_id\"),\n","    col(\"current.user_id\"),\n","    col(\"current.agent_id\"),\n","    col(\"current.user_question\"),\n","    col(\"current.agent_answer\"),\n","    col(\"current.turn_number\"),\n","    col(\"current.invoked_tool_name\"),\n","    col(\"current.response_time_ms\"),\n","    col(\"current.model_name\"),\n","    col(\"current.total_tokens\"),\n","    col(\"current.completion_tokens\"),\n","    col(\"current.prompt_tokens\"),\n","    col(\"current.trace_end\")\n",").agg(\n","    collect_list(\n","        when(col(\"previous.user_question\").isNotNull(),\n","             struct(\n","                 col(\"previous.user_question\").alias(\"question\"),\n","                 col(\"previous.agent_answer\").alias(\"answer\"),\n","                 col(\"previous.turn_number\").alias(\"turn\")\n","             )\n","        )\n","    ).alias(\"conversation_history\")\n",")\n","\n","print(f\"Built conversation context for {df_with_history.count()} Q&A pairs\")\n","\n","# ============================================================================\n","# Filter out Already Evaluated Pairs\n","# ============================================================================\n","print(\"\\n\" + \"=\"*80)\n","print(\"IDENTIFYING NEW Q&A PAIRS TO EVALUATE\")\n","print(\"=\"*80)\n","\n","df_new_qa_pairs = df_with_history.join(\n","    df_already_evaluated,\n","    df_with_history[\"agent_trace_id\"] == df_already_evaluated[\"agent_trace_id\"],\n","    \"left_anti\"\n",")\n","\n","new_pairs_count = df_new_qa_pairs.count()\n","print(f\"New Q&A pairs to evaluate: {new_pairs_count}\")\n","print(f\"Already evaluated: {total_qa_pairs - new_pairs_count}\")\n","\n","if new_pairs_count == 0:\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"✓ NO NEW Q&A PAIRS TO EVALUATE\")\n","    print(\"All existing Q&A pairs have already been scored.\")\n","    print(\"=\"*80)\n","else:\n","    print(\"\\nSample of new Q&A pairs to be evaluated (with context):\")\n","    df_new_qa_pairs.select(\n","        \"agent_trace_id\",\n","        \"turn_number\",\n","        \"user_question\",\n","        \"agent_answer\",\n","        \"conversation_history\"\n","    ).show(3, truncate=80)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":36,"statement_ids":[36],"state":"finished","livy_statement_state":"available","session_id":"8c9e2af0-7250-4f02-a681-e3c8af94e018","normalized_state":"finished","queued_time":"2025-11-11T02:02:46.7295085Z","session_start_time":null,"execution_start_time":"2025-11-11T02:02:49.0408343Z","execution_finish_time":"2025-11-11T02:03:01.9089433Z","parent_msg_id":"65b4cdb2-5ae4-4188-a8da-cdbf17dea33b"},"text/plain":"StatementMeta(, 8c9e2af0-7250-4f02-a681-e3c8af94e018, 36, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["! Scores table 'dbo.AnswerQualityScores_WithContext' doesn't exist yet - will be created on first run\n! Aligned Q&A table 'dbo.chat_qa_pairs_aligned' doesn't exist yet - will be created on first run\n\n================================================================================\nFIRST RUN: No existing evaluations found\n================================================================================\n\n================================================================================\nBUILDING Q&A PAIRS WITH CONVERSATION CONTEXT\n================================================================================\nTotal messages in chat history: 197\nTotal conversation messages: 51\nTotal Q&A pairs: 25\nBuilt conversation context for 25 Q&A pairs\n\n================================================================================\nIDENTIFYING NEW Q&A PAIRS TO EVALUATE\n================================================================================\nNew Q&A pairs to evaluate: 25\nAlready evaluated: 0\n\nSample of new Q&A pairs to be evaluated (with context):\n+------------------------------------+-----------+-------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n|                      agent_trace_id|turn_number|                                    user_question|                                                                    agent_answer|                                                            conversation_history|\n+------------------------------------+-----------+-------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n|532e0089-a82b-4be6-8532-3b14e00afeec|         13|What has been my overall income in 2025 by month?|             Here is your overall income in 2025 by month:\\n- 2025-06 - $1300.00|[{And how much did I get as gift in 2025?, You received $600.00 in gifts in 2...|\n|2ed66f2c-fb09-4aa1-aada-d720484b8d3e|          4|                                            Hello|Hi — welcome! How can I help you today? You can ask me to:\\n\\n- View your acc...|[{How much did I spend in Pharmacy?, Do you mean spending in the Pharmacy cat...|\n|1cd3d51a-9632-4a3c-be2c-e4c702da0e59|          1|                                            Hello|Hi — welcome! How can I help you today? (You can ask about your accounts, rec...|                                                                              []|\n+------------------------------------+-----------+-------------------------------------------------+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\nonly showing top 3 rows\n\n"]}],"execution_count":24,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3242974e-b80d-4339-8998-4c6234ed1561"},{"cell_type":"code","source":["# ## Step 4: Initialize Azure AI Evaluation Configuration\n","# Initialize model configuration for evaluators using dictionary format\n","# This is the correct format for newer versions of azure-ai-evaluation\n","model_config = {\n","    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n","    \"api_key\": os.environ.get(\"AZURE_OPENAI_KEY\"),\n","    \"api_version\": os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n","    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\")\n","}\n","\n","print(f\"Model configuration initialized for endpoint: {os.environ.get('AZURE_OPENAI_ENDPOINT')}\")\n","\n","# Initialize evaluators\n","intent_resolution = IntentResolutionEvaluator(model_config=model_config)\n","\n","relevance = RelevanceEvaluator(model_config=model_config)\n","coherence = CoherenceEvaluator(model_config=model_config)\n","fluency = FluencyEvaluator(model_config=model_config)\n","\n","print(\"Evaluators initialized successfully\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":37,"statement_ids":[37],"state":"finished","livy_statement_state":"available","session_id":"8c9e2af0-7250-4f02-a681-e3c8af94e018","normalized_state":"finished","queued_time":"2025-11-11T02:02:46.7810562Z","session_start_time":null,"execution_start_time":"2025-11-11T02:03:01.9111634Z","execution_finish_time":"2025-11-11T02:03:02.2434645Z","parent_msg_id":"10e11b08-1323-401d-9a88-09b02fd00d49"},"text/plain":"StatementMeta(, 8c9e2af0-7250-4f02-a681-e3c8af94e018, 37, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model configuration initialized for endpoint: https://arnaudaihub2918240993.openai.azure.com/\nEvaluators initialized successfully\n"]}],"execution_count":25,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"149046df-84a5-4792-a877-9740a68ff83e"},{"cell_type":"code","source":["# ## Step 5: Define Evaluation Function Using Azure AI SDK\n","\n","# Get Azure OpenAI credentials to pass to UDF\n","azure_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n","api_key = os.environ.get(\"AZURE_OPENAI_KEY\")\n","api_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\")\n","deployment_name = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\")\n","\n","print(f\"\\nUDF will use:\")\n","print(f\"  Endpoint: {azure_endpoint}\")\n","print(f\"  API Version: {api_version}\")\n","print(f\"  Deployment: {deployment_name}\")\n","print(f\"  API Key: {'***' if api_key else 'NOT SET'}\")\n","\n","def evaluate_with_azure_ai_sdk(conversation_history, current_question, current_answer):\n","    \"\"\"\n","    Evaluates Q&A pairs using Azure AI Evaluation SDK evaluators.\n","    Returns a dictionary with all evaluation scores.\n","    \"\"\"\n","    if not current_question or not current_answer:\n","        return {\n","            \"intent_resolution\": None,\n","            \"task_adherence\": None,\n","            \"relevance\": None,\n","            \"coherence\": None,\n","            \"fluency\": None,\n","            \"intent_resolution_reason\": \"\",\n","            \"relevance_reason\": \"\",\n","            \"coherence_reason\": \"\",\n","            \"fluency_reason\": \"\",\n","            \"evaluation_error\": \"Missing question or answer\"\n","        }\n","    \n","    try:\n","        # Re-initialize model config and evaluators inside UDF (for Spark executor)\n","        from azure.ai.evaluation import (\n","            IntentResolutionEvaluator,\n","            RelevanceEvaluator,\n","            CoherenceEvaluator,\n","            FluencyEvaluator\n","        )\n","        \n","        # Use dictionary-based model configuration (newer SDK format)\n","        # This prevents the max_tokens error with newer OpenAI models\n","        model_config = {\n","            \"azure_endpoint\": azure_endpoint,\n","            \"api_key\": api_key,\n","            \"api_version\": api_version,\n","            \"azure_deployment\": deployment_name\n","        }\n","        \n","        # Initialize evaluators\n","        intent_resolution_eval = IntentResolutionEvaluator(\n","            model_config=model_config\n","        )\n","        relevance_eval = RelevanceEvaluator(\n","            model_config=model_config\n","        )\n","        coherence_eval = CoherenceEvaluator(\n","            model_config=model_config\n","        )\n","        fluency_eval = FluencyEvaluator(\n","            model_config=model_config\n","        )\n","        \n","        # Build conversation context for evaluators that support it\n","        context_messages = []\n","        \n","        # Add conversation history if exists\n","        if conversation_history and len(conversation_history) > 0:\n","            # Convert Spark Rows to dictionaries and sort by turn number\n","            try:\n","                # Handle both dict and Row objects\n","                history_list = []\n","                for exchange in conversation_history:\n","                    if hasattr(exchange, 'asDict'):\n","                        # It's a Spark Row, convert to dict\n","                        history_list.append(exchange.asDict())\n","                    else:\n","                        # Already a dict\n","                        history_list.append(exchange)\n","                \n","                # Sort by turn number\n","                sorted_history = sorted(history_list, key=lambda x: x.get('turn', 0))\n","                \n","                for exchange in sorted_history:\n","                    context_messages.append({\n","                        \"role\": \"user\",\n","                        \"content\": exchange.get(\"question\", \"\")\n","                    })\n","                    context_messages.append({\n","                        \"role\": \"assistant\",\n","                        \"content\": exchange.get(\"answer\", \"\")\n","                    })\n","            except Exception as e:\n","                # If there's any issue with history, just skip it\n","                pass\n","        \n","        # Current exchange\n","        context_messages.append({\n","            \"role\": \"user\",\n","            \"content\": current_question\n","        })\n","        context_messages.append({\n","            \"role\": \"assistant\",\n","            \"content\": current_answer\n","        })\n","        \n","        # Run evaluators\n","        results = {}\n","        \n","        # Intent Resolution (supports message format)\n","        try:\n","            intent_result = intent_resolution_eval(\n","                query=current_question,\n","                response=current_answer\n","            )\n","            # The evaluator returns a dict with 'intent_resolution' key\n","            if isinstance(intent_result, dict):\n","                results[\"intent_resolution\"] = intent_result.get(\"intent_resolution\", None)\n","                results[\"intent_resolution_reason\"] = intent_result.get(\"intent_resolution_reason\", \"\")\n","                results[\"intent_resolution_result\"] = intent_result.get(\"intent_resolution_result\", \"\")\n","                results[\"intent_resolution_threshold\"] = intent_result.get(\"intent_resolution_threshold\", None)\n","            elif isinstance(intent_result, (int, float)):\n","                results[\"intent_resolution\"] = float(intent_result)  # Keep as float\n","                results[\"intent_resolution_reason\"] = \"Evaluated successfully\"\n","                results[\"intent_resolution_result\"] = \"pass\" if intent_result >= 3 else \"fail\"\n","                results[\"intent_resolution_threshold\"] = 3.0\n","            else:\n","                results[\"intent_resolution\"] = None\n","                results[\"intent_resolution_reason\"] = f\"Unexpected result type: {type(intent_result)}\"\n","                results[\"intent_resolution_result\"] = \"\"\n","                results[\"intent_resolution_threshold\"] = None\n","        except Exception as e:\n","            results[\"intent_resolution\"] = None\n","            results[\"intent_resolution_reason\"] = f\"Error: {str(e)}\"\n","            results[\"intent_resolution_result\"] = \"\"\n","            results[\"intent_resolution_threshold\"] = None\n","        \n","        # Relevance\n","        try:\n","            relevance_result = relevance_eval(\n","                query=current_question,\n","                response=current_answer\n","            )\n","            if isinstance(relevance_result, dict):\n","                results[\"relevance\"] = relevance_result.get(\"relevance\", None)\n","                results[\"relevance_reason\"] = relevance_result.get(\"relevance_reason\", \"\")\n","                results[\"relevance_result\"] = relevance_result.get(\"relevance_result\", \"\")\n","                results[\"relevance_threshold\"] = relevance_result.get(\"relevance_threshold\", None)\n","            elif isinstance(relevance_result, (int, float)):\n","                results[\"relevance\"] = float(relevance_result)  # Keep as float\n","                results[\"relevance_reason\"] = \"Evaluated successfully\"\n","                results[\"relevance_result\"] = \"pass\" if relevance_result >= 3 else \"fail\"\n","                results[\"relevance_threshold\"] = 3.0\n","            else:\n","                results[\"relevance\"] = None\n","                results[\"relevance_reason\"] = f\"Unexpected result type: {type(relevance_result)}\"\n","                results[\"relevance_result\"] = \"\"\n","                results[\"relevance_threshold\"] = None\n","        except Exception as e:\n","            results[\"relevance\"] = None\n","            results[\"relevance_reason\"] = f\"Error: {str(e)}\"\n","            results[\"relevance_result\"] = \"\"\n","            results[\"relevance_threshold\"] = None\n","        \n","        # Coherence\n","        try:\n","            coherence_result = coherence_eval(\n","                query=current_question,\n","                response=current_answer\n","            )\n","            if isinstance(coherence_result, dict):\n","                results[\"coherence\"] = coherence_result.get(\"coherence\", None)\n","                results[\"coherence_reason\"] = coherence_result.get(\"coherence_reason\", \"\")\n","                results[\"coherence_result\"] = coherence_result.get(\"coherence_result\", \"\")\n","                results[\"coherence_threshold\"] = coherence_result.get(\"coherence_threshold\", None)\n","            elif isinstance(coherence_result, (int, float)):\n","                results[\"coherence\"] = float(coherence_result)  # Keep as float\n","                results[\"coherence_reason\"] = \"Evaluated successfully\"\n","                results[\"coherence_result\"] = \"pass\" if coherence_result >= 3 else \"fail\"\n","                results[\"coherence_threshold\"] = 3.0\n","            else:\n","                results[\"coherence\"] = None\n","                results[\"coherence_reason\"] = f\"Unexpected result type: {type(coherence_result)}\"\n","                results[\"coherence_result\"] = \"\"\n","                results[\"coherence_threshold\"] = None\n","        except Exception as e:\n","            results[\"coherence\"] = None\n","            results[\"coherence_reason\"] = f\"Error: {str(e)}\"\n","            results[\"coherence_result\"] = \"\"\n","            results[\"coherence_threshold\"] = None\n","        \n","        # Fluency\n","        try:\n","            fluency_result = fluency_eval(\n","                query=current_question,\n","                response=current_answer\n","            )\n","            if isinstance(fluency_result, dict):\n","                results[\"fluency\"] = fluency_result.get(\"fluency\", None)\n","                results[\"fluency_reason\"] = fluency_result.get(\"fluency_reason\", \"\")\n","                results[\"fluency_result\"] = fluency_result.get(\"fluency_result\", \"\")\n","                results[\"fluency_threshold\"] = fluency_result.get(\"fluency_threshold\", None)\n","            elif isinstance(fluency_result, (int, float)):\n","                results[\"fluency\"] = float(fluency_result)  # Keep as float\n","                results[\"fluency_reason\"] = \"Evaluated successfully\"\n","                results[\"fluency_result\"] = \"pass\" if fluency_result >= 3 else \"fail\"\n","                results[\"fluency_threshold\"] = 3.0\n","            else:\n","                results[\"fluency\"] = None\n","                results[\"fluency_reason\"] = f\"Unexpected result type: {type(fluency_result)}\"\n","                results[\"fluency_result\"] = \"\"\n","                results[\"fluency_threshold\"] = None\n","        except Exception as e:\n","            results[\"fluency\"] = None\n","            results[\"fluency_reason\"] = f\"Error: {str(e)}\"\n","            results[\"fluency_result\"] = \"\"\n","            results[\"fluency_threshold\"] = None\n","        \n","        results[\"evaluation_error\"] = None\n","        return results\n","        \n","    except Exception as e:\n","        return {\n","            \"intent_resolution\": None,\n","            \"task_adherence\": None,\n","            \"relevance\": None,\n","            \"coherence\": None,\n","            \"fluency\": None,\n","            \"intent_resolution_reason\": \"\",\n","            \"relevance_reason\": \"\",\n","            \"coherence_reason\": \"\",\n","            \"fluency_reason\": \"\",\n","            \"evaluation_error\": f\"Evaluation failed: {repr(e)}\" # <-- CHANGED to repr(e)\n","        }"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":38,"statement_ids":[38],"state":"finished","livy_statement_state":"available","session_id":"8c9e2af0-7250-4f02-a681-e3c8af94e018","normalized_state":"finished","queued_time":"2025-11-11T02:02:46.8671271Z","session_start_time":null,"execution_start_time":"2025-11-11T02:03:02.2462074Z","execution_finish_time":"2025-11-11T02:03:02.6588468Z","parent_msg_id":"c8d494a8-0566-47e1-a202-cc6891ee0c24"},"text/plain":"StatementMeta(, 8c9e2af0-7250-4f02-a681-e3c8af94e018, 38, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\nUDF will use:\n  Endpoint: https://arnaudaihub2918240993.openai.azure.com/\n  API Version: 2024-10-21\n  Deployment: gpt-4.1\n  API Key: ***\n"]}],"execution_count":26,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3bed3aa0-f805-4718-801d-c9f26f957d6f"},{"cell_type":"code","source":["# ## Step 6: Create Spark UDF for Evaluation\n","\n","# Define schema for evaluation results with additional metadata\n","evaluation_schema = StructType([\n","    StructField(\"intent_resolution\", FloatType(), True),\n","    StructField(\"intent_resolution_reason\", StringType(), True),\n","    StructField(\"intent_resolution_result\", StringType(), True),  # pass/fail\n","    StructField(\"intent_resolution_threshold\", FloatType(), True),\n","    \n","    StructField(\"relevance\", FloatType(), True),\n","    StructField(\"relevance_reason\", StringType(), True),\n","    StructField(\"relevance_result\", StringType(), True),  # pass/fail\n","    StructField(\"relevance_threshold\", FloatType(), True),\n","    \n","    StructField(\"coherence\", FloatType(), True),\n","    StructField(\"coherence_reason\", StringType(), True),\n","    StructField(\"coherence_result\", StringType(), True),  # pass/fail\n","    StructField(\"coherence_threshold\", FloatType(), True),\n","    \n","    StructField(\"fluency\", FloatType(), True),\n","    StructField(\"fluency_reason\", StringType(), True),\n","    StructField(\"fluency_result\", StringType(), True),  # pass/fail\n","    StructField(\"fluency_threshold\", FloatType(), True),\n","    \n","    StructField(\"evaluation_error\", StringType(), True)\n","])\n","\n","# Create UDF\n","evaluate_udf = udf(evaluate_with_azure_ai_sdk, evaluation_schema)\n","\n","print(\"Evaluation UDF created successfully\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":39,"statement_ids":[39],"state":"finished","livy_statement_state":"available","session_id":"8c9e2af0-7250-4f02-a681-e3c8af94e018","normalized_state":"finished","queued_time":"2025-11-11T02:02:46.902587Z","session_start_time":null,"execution_start_time":"2025-11-11T02:03:02.6609645Z","execution_finish_time":"2025-11-11T02:03:03.0395717Z","parent_msg_id":"9fe73676-51e9-4d03-9351-2ae5d556373a"},"text/plain":"StatementMeta(, 8c9e2af0-7250-4f02-a681-e3c8af94e018, 39, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Evaluation UDF created successfully\n"]}],"execution_count":27,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e56c401f-3089-4df2-b928-a6adc9db4b6b"},{"cell_type":"code","source":["# ## Step 7: Evaluate New Q&A Pairs\n","\n","# This cell depends on 'new_pairs_count' and 'df_new_qa_pairs'\n","# from the data preparation cell (Step 4)\n","\n","if new_pairs_count > 0:\n","    print(\"\\n\" + \"=\"*80)\n","    print(f\"EVALUATING {new_pairs_count} NEW Q&A PAIRS WITH AZURE AI SDK\")\n","    print(\"=\"*80)\n","    \n","    # Generate run ID\n","    run_timestamp = datetime.now().isoformat()\n","    current_run_id = f\"azure_ai_sdk_run_{run_timestamp}\"\n","    \n","    print(f\"Evaluation run ID: {current_run_id}\")\n","    print(\"Starting evaluation (this may take a few minutes)...\")\n","    \n","    # Apply evaluation UDF\n","    df_scored = df_new_qa_pairs.withColumn(\n","        \"evaluation_results\",\n","        evaluate_udf(\n","            col(\"conversation_history\"),\n","            col(\"user_question\"),\n","            col(\"agent_answer\")\n","        )\n","    )\n","    \n","    # Flatten the results\n","    df_new_scores = df_scored.select(\n","        \"agent_trace_id\",\n","        \"session_id\",\n","        \"user_id\",\n","        \"agent_id\",\n","        \"turn_number\",\n","        \"user_question\",\n","        \"agent_answer\",\n","        \"invoked_tool_name\",\n","        \"response_time_ms\",\n","        \"model_name\",\n","        \"total_tokens\",\n","        \"completion_tokens\",\n","        \"prompt_tokens\",\n","        \"trace_end\",\n","        col(\"evaluation_results.intent_resolution\").alias(\"intent_resolution\"),\n","        col(\"evaluation_results.intent_resolution_reason\").alias(\"intent_resolution_reason\"),\n","        col(\"evaluation_results.intent_resolution_result\").alias(\"intent_resolution_result\"),\n","        col(\"evaluation_results.intent_resolution_threshold\").alias(\"intent_resolution_threshold\"),\n","        col(\"evaluation_results.relevance\").alias(\"relevance\"),\n","        col(\"evaluation_results.relevance_reason\").alias(\"relevance_reason\"),\n","        col(\"evaluation_results.relevance_result\").alias(\"relevance_result\"),\n","        col(\"evaluation_results.relevance_threshold\").alias(\"relevance_threshold\"),\n","        col(\"evaluation_results.coherence\").alias(\"coherence\"),\n","        col(\"evaluation_results.coherence_reason\").alias(\"coherence_reason\"),\n","        col(\"evaluation_results.coherence_result\").alias(\"coherence_result\"),\n","        col(\"evaluation_results.coherence_threshold\").alias(\"coherence_threshold\"),\n","        col(\"evaluation_results.fluency\").alias(\"fluency\"),\n","        col(\"evaluation_results.fluency_reason\").alias(\"fluency_reason\"),\n","        col(\"evaluation_results.fluency_result\").alias(\"fluency_result\"),\n","        col(\"evaluation_results.fluency_threshold\").alias(\"fluency_threshold\"),\n","        col(\"evaluation_results.evaluation_error\").alias(\"evaluation_error\")\n","    ).withColumn(\n","        \"evaluated_at\",\n","        current_timestamp()\n","    ).withColumn(\n","        \"evaluation_run_id\",\n","        lit(current_run_id)\n","    ).withColumn(\n","        \"evaluation_method\",\n","        lit(\"azure_ai_sdk_with_context\")\n","    )\n","    \n","    # Cache results to avoid re-computation\n","    print(\"Caching evaluation results...\")\n","    df_new_scores.cache()\n","    cache_count = df_new_scores.count()\n","    print(f\"✓ Caching complete. {cache_count} rows processed.\")\n","    \n","    # Debug: Show raw evaluation results before saving\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"DEBUG: RAW EVALUATION RESULTS (First 3 rows)\")\n","    print(\"=\"*80)\n","    df_new_scores.select(\n","        \"agent_trace_id\",\n","        \"intent_resolution\",\n","        \"relevance\",\n","        \"coherence\",\n","        \"fluency\",\n","        \"evaluation_error\"\n","    ).show(3, truncate=False)\n","    \n","    # Debug: Check for null values\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"DEBUG: NULL VALUE CHECK\")\n","    print(\"=\"*80)\n","    null_counts = df_new_scores.select(\n","        [sql_count(when(col(c).isNull(), c)).alias(c) \n","         for c in [\"intent_resolution\", \"relevance\", \"coherence\", \"fluency\"]]\n","    ).collect()[0].asDict()\n","    \n","    for metric, null_count in null_counts.items():\n","        total = cache_count\n","        non_null = total - null_count\n","        print(f\"  {metric}: {non_null}/{total} have values ({null_count} nulls)\")\n","    \n","    # Save to scores table\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"SAVING NEW EVALUATIONS\")\n","    print(\"=\"*80)\n","    \n","    df_new_scores.write.mode(\"append\").format(\"delta\").saveAsTable(SCORES_TABLE)\n","    print(f\"✓ Successfully appended {cache_count} new evaluations to '{SCORES_TABLE}'\")\n","    \n","    # Display sample results\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"SAMPLE EVALUATION RESULTS\")\n","    print(\"=\"*80)\n","    \n","    df_new_scores.select(\n","        \"agent_trace_id\",\n","        \"turn_number\",\n","        \"user_question\",\n","        \"intent_resolution\",\n","        \"relevance\",\n","        \"coherence\",\n","        \"fluency\"\n","    ).show(5, truncate=80)\n","    \n","    # Show reasons for a few samples\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"SAMPLE EVALUATION REASONS (with full error)\")\n","    print(\"=\"*80)\n","    \n","    df_new_scores.select(\n","        \"agent_trace_id\",\n","        \"intent_resolution_reason\",\n","        \"relevance_reason\",\n","        \"coherence_reason\",\n","        \"fluency_reason\"\n","    ).show(3, truncate=False) # Set truncate=False to see the full error\n","    \n","    # Summary statistics\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"SUMMARY STATISTICS (NEW EVALUATIONS)\")\n","    print(\"=\"*80)\n","    \n","    df_new_scores.select(\n","        \"intent_resolution\",\n","        \"relevance\",\n","        \"coherence\",\n","        \"fluency\"\n","    ).describe().show()\n","    \n","    # Check for errors\n","    error_count = df_new_scores.filter(col(\"evaluation_error\").isNotNull()).count()\n","    if error_count > 0:\n","        print(f\"\\n⚠️ Warning: {error_count} evaluations had errors\")\n","        print(\"Sample errors:\")\n","        df_new_scores.filter(col(\"evaluation_error\").isNotNull()).select(\n","            \"agent_trace_id\",\n","            \"evaluation_error\"\n","        ).show(3, truncate=False)\n","    \n","    # Clean up cache\n","    df_new_scores.unpersist()\n","elif new_pairs_count == 0:\n","    print(\"Skipping evaluation as 'new_pairs_count' is 0.\")\n","else:\n","    print(\"Skipping evaluation as 'new_pairs_count' is not defined.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":40,"statement_ids":[40],"state":"finished","livy_statement_state":"available","session_id":"8c9e2af0-7250-4f02-a681-e3c8af94e018","normalized_state":"finished","queued_time":"2025-11-11T02:02:46.9504295Z","session_start_time":null,"execution_start_time":"2025-11-11T02:03:03.0415882Z","execution_finish_time":"2025-11-11T02:04:38.081486Z","parent_msg_id":"0c917504-3fd8-4a0b-a5c2-44c21921b66b"},"text/plain":"StatementMeta(, 8c9e2af0-7250-4f02-a681-e3c8af94e018, 40, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n================================================================================\nEVALUATING 25 NEW Q&A PAIRS WITH AZURE AI SDK\n================================================================================\nEvaluation run ID: azure_ai_sdk_run_2025-11-11T02:03:03.173865\nStarting evaluation (this may take a few minutes)...\nCaching evaluation results...\n✓ Caching complete. 25 rows processed.\n\n================================================================================\nDEBUG: RAW EVALUATION RESULTS (First 3 rows)\n================================================================================\n+------------------------------------+-----------------+---------+---------+-------+----------------+\n|agent_trace_id                      |intent_resolution|relevance|coherence|fluency|evaluation_error|\n+------------------------------------+-----------------+---------+---------+-------+----------------+\n|2ed66f2c-fb09-4aa1-aada-d720484b8d3e|5.0              |5.0      |4.0      |4.0    |NULL            |\n|1cd3d51a-9632-4a3c-be2c-e4c702da0e59|5.0              |5.0      |4.0      |3.0    |NULL            |\n|94f123eb-2af6-45f6-b3f6-3dbb3774c9f9|3.0              |5.0      |4.0      |4.0    |NULL            |\n+------------------------------------+-----------------+---------+---------+-------+----------------+\nonly showing top 3 rows\n\n\n================================================================================\nDEBUG: NULL VALUE CHECK\n================================================================================\n  intent_resolution: 25/25 have values (0 nulls)\n  relevance: 25/25 have values (0 nulls)\n  coherence: 25/25 have values (0 nulls)\n  fluency: 25/25 have values (0 nulls)\n\n================================================================================\nSAVING NEW EVALUATIONS\n================================================================================\n✓ Successfully appended 25 new evaluations to 'dbo.AnswerQualityScores_WithContext'\n\n================================================================================\nSAMPLE EVALUATION RESULTS\n================================================================================\n+------------------------------------+-----------+---------------------------------------------------+-----------------+---------+---------+-------+\n|                      agent_trace_id|turn_number|                                      user_question|intent_resolution|relevance|coherence|fluency|\n+------------------------------------+-----------+---------------------------------------------------+-----------------+---------+---------+-------+\n|2ed66f2c-fb09-4aa1-aada-d720484b8d3e|          4|                                              Hello|              5.0|      5.0|      4.0|    4.0|\n|1cd3d51a-9632-4a3c-be2c-e4c702da0e59|          1|                                              Hello|              5.0|      5.0|      4.0|    3.0|\n|94f123eb-2af6-45f6-b3f6-3dbb3774c9f9|          1|             Can you show my last ten transactions?|              3.0|      5.0|      4.0|    4.0|\n|c2f6981c-09a0-4a8f-b3cb-1fb41cf17a5e|          7|              Can you show my last 10 transactions?|              3.0|      3.0|      4.0|    3.0|\n|9de4e8ab-e4d8-45e1-94bd-c3e59ab35584|          1|What are the fees for late payment on credit cards?|              2.0|      2.0|      4.0|    4.0|\n+------------------------------------+-----------+---------------------------------------------------+-----------------+---------+---------+-------+\nonly showing top 5 rows\n\n\n================================================================================\nSAMPLE EVALUATION REASONS (with full error)\n================================================================================\n+------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|agent_trace_id                      |intent_resolution_reason                                                                                                                                                                                                                                                         |relevance_reason                                                                                                                                                                                                                                                                       |coherence_reason                                                                                                                                                                                        |fluency_reason                                                                                                                                                                                                                                             |\n+------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|2ed66f2c-fb09-4aa1-aada-d720484b8d3e|The user simply greeted the agent with 'Hello.' The agent responded with a friendly greeting and a clear menu of available actions, appropriately prompting the user for their next intent. This fully resolves the user's initial greeting.                                     |The response is highly relevant to the user's greeting, offering a friendly welcome and outlining possible actions the user can take. It anticipates user needs and provides clear next steps, making it a comprehensive and insightful reply for an initial interaction.              |The response is coherent, well-organized, and flows smoothly, making it easy for the user to understand what to do next after saying \"Hello.\"                                                           |The response is well-articulated, clear, and coherent, with good grammar and logical flow, fitting the definition of Proficient Fluency.                                                                                                                   |\n|1cd3d51a-9632-4a3c-be2c-e4c702da0e59|User greeted the agent with 'Hello.' The agent responded with a friendly welcome and provided options for further assistance, appropriately prompting the user to specify their intent. This is a suitable and complete resolution for an initial greeting.                      |The response is highly relevant to the user's greeting, offering a friendly welcome and listing specific banking-related topics the user can ask about, which adds helpful context and options.                                                                                        |The response is logically structured, flows smoothly, and clearly connects the greeting to the offered assistance, making it coherent and easy to understand.                                           |The response is clear, correct, and coherent, but lacks complexity and advanced vocabulary, fitting the definition of \"Competent Fluency.\"                                                                                                                 |\n|94f123eb-2af6-45f6-b3f6-3dbb3774c9f9|User wanted to see their last ten transactions. The agent failed to provide them due to a database error but explained the issue, confirmed account details, and offered actionable next steps. The intent is not resolved, but the agent facilitates progress toward resolution.|The response is directly related to the user's request for their last ten transactions. It explains the attempt, the error encountered, and offers actionable next steps, including retrying, narrowing the query, or escalating. This is a thorough, helpful, and context-aware reply.|The response is coherent, well-organized, and easy to follow, with clear logical connections and transitions between ideas. It thoroughly addresses the user's query and provides actionable next steps.|This response demonstrates proficient fluency with strong grammar, varied vocabulary, and clear, logical structure. It is well-articulated and easy to understand, though it does not reach the level of exceptional eloquence or stylistic sophistication.|\n+------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nonly showing top 3 rows\n\n\n================================================================================\nSUMMARY STATISTICS (NEW EVALUATIONS)\n================================================================================\n+-------+------------------+------------------+-------------------+------------------+\n|summary| intent_resolution|         relevance|          coherence|           fluency|\n+-------+------------------+------------------+-------------------+------------------+\n|  count|                25|                25|                 25|                25|\n|   mean|              4.12|              4.12|               3.96|              3.64|\n| stddev|1.1661903789690602|0.8326663997864531|0.35118845842842455|0.5686240703077327|\n|    min|               2.0|               2.0|                3.0|               2.0|\n|    max|               5.0|               5.0|                5.0|               4.0|\n+-------+------------------+------------------+-------------------+------------------+\n\n"]}],"execution_count":28,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"advisor":{"adviceMetadata":"{\"artifactId\":\"fe146ce3-47ac-4530-b596-12d6d0c7bbb0\",\"activityId\":\"8c9e2af0-7250-4f02-a681-e3c8af94e018\",\"applicationId\":\"application_1762824850341_0001\",\"jobGroupId\":\"40\",\"advices\":{\"warn\":1}}"}},"id":"db040bc7-6f00-4124-9d7b-98a2c788b5fb"},{"cell_type":"code","source":["# ## Step 8: Overall Statistics and Analysis\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"OVERALL EVALUATION STATISTICS\")\n","print(\"=\"*80)\n","\n","try:\n","    df_all_scores = spark.read.table(SCORES_TABLE)\n","    total_evaluated = df_all_scores.count()\n","    \n","    print(f\"Total Q&A pairs evaluated (all time): {total_evaluated}\")\n","    \n","    # Re-read new_pairs_count if kernel restarted, or use 0 if no new pairs were evaluated\n","    try:\n","        current_run_new_pairs = new_pairs_count\n","    except NameError:\n","        current_run_new_pairs = 0 # Assume 0 if variable is lost\n","\n","    print(f\"New pairs evaluated in this run: {current_run_new_pairs}\")\n","    \n","    # Overall averages\n","    df_overall_stats = df_all_scores.agg(\n","        sql_count(\"*\").alias(\"total_evaluations\"),\n","        avg(\"intent_resolution\").alias(\"avg_intent_resolution\"),\n","        avg(\"relevance\").alias(\"avg_relevance\"),\n","        avg(\"coherence\").alias(\"avg_coherence\"),\n","        avg(\"fluency\").alias(\"avg_fluency\"),\n","        avg(\"response_time_ms\").alias(\"avg_response_time_ms\")\n","    )\n","    \n","    print(\"\\nOverall averages:\")\n","    df_overall_stats.show()\n","    \n","    # Compare first turn vs. follow-up turns\n","    print(\"\\n\" + \"=\"*80)\n","    print(\"COMPARISON: First Turn vs. Follow-up Turns\")\n","    print(\"=\"*80)\n","    \n","    df_all_scores.withColumn(\n","        \"turn_type\",\n","        when(col(\"turn_number\") == 1, \"First Turn\").otherwise(\"Follow-up\")\n","    ).groupBy(\"turn_type\").agg(\n","        sql_count(\"*\").alias(\"count\"),\n","        avg(\"intent_resolution\").alias(\"avg_intent_resolution\"),\n","        avg(\"relevance\").alias(\"avg_relevance\"),\n","        avg(\"coherence\").alias(\"avg_coherence\"),\n","        avg(\"fluency\").alias(\"avg_fluency\")\n","    ).show()\n","    \n","    # Check for evaluation errors\n","    total_errors = df_all_scores.filter(col(\"evaluation_error\").isNotNull()).count()\n","    if total_errors > 0:\n","        print(f\"\\n⚠️ Total evaluations with errors: {total_errors}\")\n","    \n","except Exception as e:\n","    print(f\"Could not load overall statistics: {e}\")\n","\n","print(\"\\n\" + \"=\"*80)\n","print(\"✓ AZURE AI SDK EVALUATION COMPLETE\")\n","print(\"=\"*80)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":41,"statement_ids":[41],"state":"finished","livy_statement_state":"available","session_id":"8c9e2af0-7250-4f02-a681-e3c8af94e018","normalized_state":"finished","queued_time":"2025-11-11T02:02:46.983604Z","session_start_time":null,"execution_start_time":"2025-11-11T02:04:38.0839338Z","execution_finish_time":"2025-11-11T02:04:43.4212816Z","parent_msg_id":"565b71ca-a4b3-41f7-b620-62ba155ecb3f"},"text/plain":"StatementMeta(, 8c9e2af0-7250-4f02-a681-e3c8af94e018, 41, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n================================================================================\nOVERALL EVALUATION STATISTICS\n================================================================================\nTotal Q&A pairs evaluated (all time): 25\nNew pairs evaluated in this run: 25\n\nOverall averages:\n+-----------------+---------------------+-------------+-------------+-----------+--------------------+\n|total_evaluations|avg_intent_resolution|avg_relevance|avg_coherence|avg_fluency|avg_response_time_ms|\n+-----------------+---------------------+-------------+-------------+-----------+--------------------+\n|               25|                 4.12|         4.12|         3.96|       3.64|            30892.24|\n+-----------------+---------------------+-------------+-------------+-----------+--------------------+\n\n\n================================================================================\nCOMPARISON: First Turn vs. Follow-up Turns\n================================================================================\n+----------+-----+---------------------+-------------+-----------------+-----------------+\n| turn_type|count|avg_intent_resolution|avg_relevance|    avg_coherence|      avg_fluency|\n+----------+-----+---------------------+-------------+-----------------+-----------------+\n|First Turn|   10|                  4.3|          4.0|              4.0|              3.8|\n| Follow-up|   15|                  4.0|          4.2|3.933333333333333|3.533333333333333|\n+----------+-----+---------------------+-------------+-----------------+-----------------+\n\n\n================================================================================\n✓ AZURE AI SDK EVALUATION COMPLETE\n================================================================================\n"]}],"execution_count":29,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4523cb84-204d-4f2a-9ded-f5e5cdf02323"},{"cell_type":"code","source":["# ## Step 9: Advanced Analysis - Score Distribution\n","\n","try:\n","    if 'df_all_scores' in locals() and total_evaluated > 0:\n","        print(\"\\n\" + \"=\"*80)\n","        print(\"SCORE DISTRIBUTION ANALYSIS\")\n","        print(\"=\"*80)\n","        \n","        # Score distribution for each metric\n","        metrics = [\"intent_resolution\", \"relevance\", \"coherence\", \"fluency\"]\n","        \n","        for metric in metrics:\n","            print(f\"\\n{metric.upper().replace('_', ' ')} Score Distribution:\")\n","            df_all_scores.filter(col(metric).isNotNull()).groupBy(metric).count().orderBy(metric).show()\n","    else:\n","        print(\"Skipping score distribution analysis as no scores are loaded.\")\n","except Exception as e:\n","    print(f\"Could not run score distribution analysis: {e}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":42,"statement_ids":[42],"state":"finished","livy_statement_state":"available","session_id":"8c9e2af0-7250-4f02-a681-e3c8af94e018","normalized_state":"finished","queued_time":"2025-11-11T02:02:47.0285587Z","session_start_time":null,"execution_start_time":"2025-11-11T02:04:43.423462Z","execution_finish_time":"2025-11-11T02:04:47.3075098Z","parent_msg_id":"cee46025-82f7-417b-925d-4998cd56cca0"},"text/plain":"StatementMeta(, 8c9e2af0-7250-4f02-a681-e3c8af94e018, 42, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n================================================================================\nSCORE DISTRIBUTION ANALYSIS\n================================================================================\n\nINTENT RESOLUTION Score Distribution:\n+-----------------+-----+\n|intent_resolution|count|\n+-----------------+-----+\n|              2.0|    3|\n|              3.0|    6|\n|              4.0|    1|\n|              5.0|   15|\n+-----------------+-----+\n\n\nRELEVANCE Score Distribution:\n+---------+-----+\n|relevance|count|\n+---------+-----+\n|      2.0|    1|\n|      3.0|    4|\n|      4.0|   11|\n|      5.0|    9|\n+---------+-----+\n\n\nCOHERENCE Score Distribution:\n+---------+-----+\n|coherence|count|\n+---------+-----+\n|      3.0|    2|\n|      4.0|   22|\n|      5.0|    1|\n+---------+-----+\n\n\nFLUENCY Score Distribution:\n+-------+-----+\n|fluency|count|\n+-------+-----+\n|    2.0|    1|\n|    3.0|    7|\n|    4.0|   17|\n+-------+-----+\n\n"]}],"execution_count":30,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e1c7c3f5-cb85-4f3d-8d16-1261cd80f1b0"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"9bd7710a-be1e-452c-91e1-3e9fa5158e42"}],"default_lakehouse":"9bd7710a-be1e-452c-91e1-3e9fa5158e42","default_lakehouse_name":"agentic_lake","default_lakehouse_workspace_id":"5333f29a-3d22-4d01-ad31-9dfa8bcb3ec2"}}},"nbformat":4,"nbformat_minor":5}